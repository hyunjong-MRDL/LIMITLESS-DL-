{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "import data, utils, processing, metric\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pingouin as pg\n",
    "\n",
    "root = 'E:/LIMITLESS_DL/Respiration/'\n",
    "data_root = f\"{root}DATA/\"\n",
    "result_root = f\"{root}RESULTS/\"\n",
    "\n",
    "treatment = \"STATIC\"\n",
    "breath = \"Breathhold\"\n",
    "\n",
    "patient_path, num_fx = data.patient_path(data_root, treatment, breath)\n",
    "patient_ID = patient_path.split(\"/\")[5].split(\"_\")[0]\n",
    "\n",
    "patient_path, num_fx = data.patient_path(data_root, treatment, breath)\n",
    "\n",
    "fx_levels, fx_errors = [], []\n",
    "for fx in range(1, num_fx+1):\n",
    "    fraction_path, num_fld = data.fraction_path(patient_path, fx)\n",
    "    fld_levels, fld_errors = [], []\n",
    "\n",
    "    for field in range(1, num_fld+1):\n",
    "        (data_Times, data_Amps), (beam_Times, beam_Amps) = data.read_field_data(fraction_path, field)\n",
    "        cutted_Amps = processing.cut_by_beams(data_Times, data_Amps, beam_Times)\n",
    "        enabled_intervals, num_intvs = processing.beam_enabling_intervals(data_Times, data_Amps, beam_Times)\n",
    "        beam_levels, beam_errors = [], []\n",
    "\n",
    "        for intv in range(num_intvs):\n",
    "            intv_level = metric.avg_lvl_per_interval(enabled_intervals[intv])\n",
    "            intv_error = metric.error_per_interval(enabled_intervals[intv])\n",
    "            beam_levels.append(intv_level)\n",
    "            beam_errors.append(intv_error)\n",
    "        \n",
    "        fld_levels.append(np.mean(beam_levels))\n",
    "        fld_errors.append(np.mean(beam_errors))\n",
    "\n",
    "    fx_levels.append(np.mean(fld_levels))\n",
    "    fx_errors.append(np.mean(fld_errors))\n",
    "\n",
    "print(len(fx_levels))\n",
    "print(len(fx_errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def icc(scores):\n",
    "    # Calculate number of raters (n_raters) and subjects (n_subjects)\n",
    "    n_raters = 5\n",
    "    n_subjects = 2\n",
    "\n",
    "    scores_matrix = np.array(scores).reshape(n_subjects, n_raters)\n",
    "\n",
    "    # Mean calculations\n",
    "    mean_total = np.mean(scores_matrix)  # Overall mean\n",
    "    mean_subject = np.mean(scores_matrix, axis=1)\n",
    "\n",
    "    # Variance components based on ANOVA\n",
    "    MS_subject = np.sum((mean_subject - mean_total) ** 2) * n_raters / (n_subjects - 1)\n",
    "    MS_residual = np.sum((scores_matrix - mean_subject[:, None]) ** 2) / (n_raters * (n_subjects - 1))\n",
    "\n",
    "    # ICC(1) calculation\n",
    "    icc_1 = (MS_subject - MS_residual) / (MS_subject + (n_raters - 1) * MS_residual)\n",
    "\n",
    "    print(f\"Intraclass Correlation Coefficient ICC(1): {icc_1:.4f}\")\n",
    "    return"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
